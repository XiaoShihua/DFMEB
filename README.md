# DFMEB
CCKS 2024 任务-数字金融模型评测（Digital Finance Model Evaluation Benchmark，DFMEB）
### 1. 任务简介
随着GPT的诞生，大语言模型（Large Language Model, LLM）在自然语言处理领域掀起了新一轮研究狂潮。近一年多时间，国内外大模型纷纷出炉，不断刷新人们对各项任务的认知。面对各种各样的大模型，如何评价其综合能力，成为一项热门研究任务。
为了推动LLM在数字金融领域的发展，并解决实际金融业务问题。招商银行联合中科院自动化所、科大讯飞股份有限公司，结合实际生产场景，推出数字金融领域评测基准（Digital Finance Model Evaluation Benchmark，DFMEB）。该评测基准包含六大场景（知识问答、文本理解、内容生成、逻辑推理、安全合规、AI智能体），涵盖69种金融任务，有利于帮助快速评测LLM在金融领域的表现。
### 2. 赛程安排
本次大赛分为报名组队、初赛、复赛两个阶段，具体安排和要求如下：

赛程	时间

报名组队 --- 任务发布 - 2024/7/19

初赛阶段 --- 2024/5/16 - 2024/7/19

复赛阶段 --- 2024/7/20 - 2024/8/4

审核材料提交 --- 2024/8/4 - 2024/8/8

复赛结果公布 --- 2024/8/15

评测论文提交 --- 2024/9/1 

CCKS会议 (评测报告及颁奖) --- 2024/9/19-2024/9/22

报名方式：5月16日阿里天池平台(https://tianchi.aliyun.com/) 将开放本次比赛的组队报名、登录比赛官网，完成个人信息注册，即可报名参赛；选手可以单人参赛，也可以组队参赛。组队参赛的每个团队2-3人，每位选手只能加入一支队伍；
### 3. baseline说明

（1）提供了测试所需的官方prompt模版（prompt_template.py）

（2）运行run.py即可读取数据进行测试，模型为API调用方式，参赛者亦可本地加载模型获取结果。

（3）数据集可报名参加比赛后，在天池获取。

### 4. 任务提交说明

比赛期间，参赛队伍报名成功后即可通过天池平台下载数据，本地调试LLM，在线提交结果，结果文件命名为"参赛队名称\_测试集版本(初赛或者复赛)\_result.jsonl"。提交文件以utf-8编码格式保存，每条数据需包含测试集已有字段，并将预测的答案写入answer字段中，测试的answer字典原始内容为空（""）。

样例如下：

xxx\_初赛\_result.jsonl

```
{"id": 1, "category": "知识问答", "task": "知识边界", "answer": "B", "question": "哪个券商提供最好的投资服务?", "content": "", "A": "是", "B": "否"}
......
{"id": 829,  ......}
```

